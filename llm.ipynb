{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading raw text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"the-verdict.txt\",\"r\",encoding=\"utf-8\") as file:\n",
    "    raw_text=file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "preprocessed= re.split(r'([,.:?_!\"()\\']|--|\\s)',raw_text)\n",
    "result= [items.strip() for items in preprocessed if items.split()]\n",
    "allwords=sorted(set(result))\n",
    "allwords.extend([\"<|unk|>\",\"<|endoftext|>\"])\n",
    "vocab= {word:index for index,word in enumerate(allwords)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implementation of simple tokenizer -- For understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simpleTokenizer1:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int=vocab\n",
    "        self.int_to_str={int:str for str,int in vocab.items()}\n",
    "    \n",
    "    def encode(self, text):\n",
    "        _preprocessed= re.split(r'([,.:?_!\"()\\']|--|\\s)',text)\n",
    "        _result= [items.strip() for items in _preprocessed if items.split()]\n",
    "        return [self.str_to_int[items] for items in _result]\n",
    "    \n",
    "    def decode(self, tokens):\n",
    "        text= \" \".join([self.int_to_str[items] for items in tokens])\n",
    "        text= re.sub(r'\\s([,.:?_!\"()\\']|--|\\s)',r'\\1',text)\n",
    "        return text          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1014, 58, 39]\n",
      "thought Jack Gisburn\n"
     ]
    }
   ],
   "source": [
    "tokenizer= simpleTokenizer1(vocab)\n",
    "text=\"thought Jack Gisburn\"\n",
    "encoded= tokenizer.encode(text)\n",
    "print(encoded)\n",
    "decode= tokenizer.decode(encoded)\n",
    "print(decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simpleTokenizer2:\n",
    "    def __init__(self, vocab):\n",
    "        self.int_to_str={str:int for int,str in vocab.items()}\n",
    "        self.str_to_int=vocab\n",
    "        \n",
    "    def encode(self, text):\n",
    "        preprocessed= re.split(r'([.,?!_!\"()\\']|--|\\s)',text)\n",
    "        _preprocessed= [items.strip() for items in preprocessed if items.split()]\n",
    "        encoded_text= [item if item in self.str_to_int \n",
    "                       else \"<|unk|>\" for item in _preprocessed]\n",
    "        return [self.str_to_int[items] for items in encoded_text]\n",
    "    \n",
    "    def decode(self, tokens):\n",
    "        text= \" \".join([self.int_to_str[items] for items in tokens])\n",
    "        text= re.sub(r'\\s([,.:?_!\"()\\']|--|\\s)',r'\\1',text)\n",
    "        return text \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1143, 705, 1143, 590, 1143]\n",
      "<|unk|> my <|unk|> is <|unk|>\n"
     ]
    }
   ],
   "source": [
    "tokenizer2= simpleTokenizer2(vocab)\n",
    "text=\"Hello my name is Anant\"\n",
    "encoded= tokenizer2.encode(text)\n",
    "print(encoded)\n",
    "decode= tokenizer2.decode(encoded)\n",
    "print(decode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Byte-Pair Encoding --> A type of subword encoding technique used in GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "tokenizer= tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing dataset, Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDataset_V1:\n",
    "    \n",
    "    def __init__(self, text, tokenizer, maximum_length, stride):\n",
    "        \n",
    "        self.input_ids=[]\n",
    "        self.target_ids=[] \n",
    "        \n",
    "        token_ids= tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "        \n",
    "        for i in range(0, len(token_ids)-maximum_length, stride):\n",
    "            input_tokens = token_ids[i:i+maximum_length]\n",
    "            output_tokens= token_ids[i+1:i+maximum_length+1]\n",
    "            \n",
    "            self.input_ids.append(torch.tensor(input_tokens))\n",
    "            self.target_ids.append(torch.tensor(output_tokens))\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.input_ids[index], self.target_ids[index]\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_Dataloader_V1(text, batch_size=4, maximum_length=256, stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
    "    \n",
    "    tokenizer=tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset= GPTDataset_V1(text, tokenizer, maximum_length, stride)\n",
    "\n",
    "    dataloader= DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers)\n",
    "    \n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size= 50257\n",
    "output_dim=256\n",
    "\n",
    "embedding_layer= torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length=4 \n",
    "dataLoader= Create_Dataloader_V1(raw_text, \n",
    "                                batch_size=8, \n",
    "                                maximum_length=max_length, \n",
    "                                stride=max_length, shuffle=False)\n",
    "data_iter= iter(dataLoader)\n",
    "inputs, targets= next(data_iter)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Ids: \n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token Ids: \\n\", inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inputs shape\n",
      " torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nInputs shape\\n\", inputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Self_Attention_V1:\n",
    "    \n",
    "    def __init__(self, d_in, d_out, qkv_biases=False):\n",
    "        super.__init__()\n",
    "        self.w_query=torch.Parameter(torch.nn.random(d_in, d_out, bias=qkv_biases))\n",
    "        self.w_key=torch.Parameter(torch.nn.random(d_in, d_out, bias=qkv_biases))\n",
    "        self.w_value=torch.Parameter(torch.nn.random(d_in, d_out, bias=qkv_biases))\n",
    "        \n",
    "        def forward(self, x):\n",
    "            \n",
    "            queries=self.w_query(x)\n",
    "            keys=self.w_key(x)\n",
    "            values=self.w_values(x)\n",
    "            \n",
    "            # attention= softmax([1/sqrt(d_out)*query*key^T])*value\n",
    "            \n",
    "            attention_scores= queries @ keys.T\n",
    "            attention_weight= torch.softmax(attention_scores/ keys.shape[-1]**0.5, dim=-1)\n",
    "            context_vec= attention_weight @ values\n",
    "            \n",
    "            return context_vec\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Self_Attention_V2(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_in, d_out, qkv_biases=False):\n",
    "        super.__init__()\n",
    "        self.w_query=nn.Linear(d_in, d_out, bias=qkv_biases)\n",
    "        self.w_key=nn.Linear(d_in, d_out, bias=qkv_biases)\n",
    "        self.w_values=nn.Linear(d_in, d_out, bias=qkv_biases)\n",
    "        \n",
    "        def forward(self, x):\n",
    "            \n",
    "            queries=self.w_query(x)\n",
    "            keys=self.w_key(x)\n",
    "            values=self.w_values(x)\n",
    "            \n",
    "            # attention= softmax([1/sqrt(d_out)*query*key^T])*value\n",
    "            \n",
    "            attention_scores= queries @ keys.T\n",
    "            attention_weight= torch.softmax(attention_scores/ keys.shape[-1]**0.5, dim=-1)\n",
    "            context_vec= attention_weight @ values\n",
    "            \n",
    "            return context_vec\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Causal attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Causal_Attention(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_in, d_out, context_length, dropout, qkv_biases=False):\n",
    "        super.__init__()\n",
    "        self.d_out=d_out\n",
    "        self.w_query=nn.Linear(d_in, d_out, bias=qkv_biases)\n",
    "        self.w_key=nn.Linear(d_in, d_out, bias=qkv_biases)\n",
    "        self.w_values=nn.Linear(d_in, d_out, bias=qkv_biases)\n",
    "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "        self.droout= nn.Dropout(dropout)\n",
    "        \n",
    "        def forward(self, x):\n",
    "            batch_size, num_tokens, d_in= x.shape\n",
    "            queries=self.w_query(x)\n",
    "            keys=self.w_key(x)\n",
    "            values=self.w_values(x)\n",
    "            \n",
    "            # attention= softmax([1/sqrt(d_out)*query*key^T])*value\n",
    "            \n",
    "            attention_scores= queries @ keys.transpose(1,2)\n",
    "            attention_scores.masked_fill_(\n",
    "                self.mask.bool()[:num_tokens,:num_tokens],-torch.inf\n",
    "            )\n",
    "            attention_weight= torch.softmax(attention_scores/ keys.shape[-1]**0.5, dim=-1)\n",
    "            attention_weight= self.dropout(attention_weight)\n",
    "            context_vec= attention_weight @ values\n",
    "            \n",
    "            return context_vec\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-head attention wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiheadAttentionWrapper:\n",
    "    \n",
    "    def __init__(self, d_in, d_out, context_length, num_heads, dropout,qkv_biases=False):\n",
    "        self.heads=nn.ModuleList([\n",
    "            Causal_Attention(d_in, d_out, context_length, dropout, qkv_biases) for _ in range(num_heads)]\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        combined_context_vec= torch.cat([head(x) for head in self.heads], dim=-1)\n",
    "        return combined_context_vec\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm:\n",
    "    def __init__(self, embedding_dim):\n",
    "        super.__init__()\n",
    "        self.scale= nn.Parameter(torch.ones(embedding_dim))\n",
    "        self.shift= nn.Parameter(torch.ones(embedding_dim))\n",
    "        self.eps=1e-5\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean= x.mean( dim=-1, keepdim=True)\n",
    "        var= x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x= (x-mean)/torch.sqrt(var+self.eps)\n",
    "        return norm_x*self.scale+ self.shift\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multihead Attention with weight splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiheadAttention(nn.Module):\n",
    "    def __init__(self,d_in, d_out, context_length,dropout,num_heads,qkv_bias=False):\n",
    "        \n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads==0), \"d_out must be divisible by num_heads\"\n",
    "            \n",
    "       \n",
    "        self.d_out=d_out\n",
    "        self.dropout=dropout\n",
    "        self.num_heads=num_heads\n",
    "        self.head_dim= d_out // num_heads\n",
    "\n",
    "        self.W_query=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.W_key=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        self.W_value=nn.Linear(d_in,d_out,bias=qkv_bias)\n",
    "        \n",
    "        self.out_proj=nn.Linear(d_in,d_out)\n",
    "        \n",
    "        self.register_buffer(\"mask\",\n",
    "                            torch.triu(torch.ones(context_length,context_length), diagonal=1))\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        b, num_tokens, d_in=x.shape\n",
    "        \n",
    "        keys= self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
    "        queries= self.W_query(x)\n",
    "        values= self.W_value(x)\n",
    "        \n",
    "        \n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys= keys.view(b,num_tokens,self.num_heads, self.head_dim)\n",
    "        queries=queries.view(b,num_tokens,self.num_heads, self.head_dim)\n",
    "        values= values.view(b,num_tokens,self.num_heads, self.head_dim)\n",
    "        \n",
    "       # (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys.transpose(1,2)\n",
    "        queries.transpose(1,2)\n",
    "        values.transpose(1,2)\n",
    "        \n",
    "        attention_scores= queries @ keys.transpose(2,3)\n",
    "        \n",
    "        mask_bool = self.mask.bool()[:num_tokens,:num_tokens]\n",
    "        \n",
    "        attention_scores.masked_fill_(mask_bool,-torch.inf)\n",
    "        \n",
    "        attention_weights= torch.softmax(attention_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attention_weights= self.dropout(attention_weights)\n",
    "        \n",
    "        \n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec= (attention_weights @ values).transpose(1,2)\n",
    "        \n",
    "        context_vec=context_vec.contiguous().view(b,num_tokens,self.d_out)\n",
    "        context_vec= self.out_proj(context_vec)\n",
    "        return context_vec\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
