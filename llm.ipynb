{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading raw text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"the-verdict.txt\",\"r\",encoding=\"utf-8\") as file:\n",
    "    raw_text=file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "preprocessed= re.split(r'([,.:?_!\"()\\']|--|\\s)',raw_text)\n",
    "result= [items.strip() for items in preprocessed if items.split()]\n",
    "allwords=sorted(set(result))\n",
    "allwords.extend([\"<|unk|>\",\"<|endoftext|>\"])\n",
    "vocab= {word:index for index,word in enumerate(allwords)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implementation of simple tokenizer -- For understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simpleTokenizer1:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int=vocab\n",
    "        self.int_to_str={int:str for str,int in vocab.items()}\n",
    "    \n",
    "    def encode(self, text):\n",
    "        _preprocessed= re.split(r'([,.:?_!\"()\\']|--|\\s)',text)\n",
    "        _result= [items.strip() for items in _preprocessed if items.split()]\n",
    "        return [self.str_to_int[items] for items in _result]\n",
    "    \n",
    "    def decode(self, tokens):\n",
    "        text= \" \".join([self.int_to_str[items] for items in tokens])\n",
    "        text= re.sub(r'\\s([,.:?_!\"()\\']|--|\\s)',r'\\1',text)\n",
    "        return text          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1014, 58, 39]\n",
      "thought Jack Gisburn\n"
     ]
    }
   ],
   "source": [
    "tokenizer= simpleTokenizer1(vocab)\n",
    "text=\"thought Jack Gisburn\"\n",
    "encoded= tokenizer.encode(text)\n",
    "print(encoded)\n",
    "decode= tokenizer.decode(encoded)\n",
    "print(decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simpleTokenizer2:\n",
    "    def __init__(self, vocab):\n",
    "        self.int_to_str={str:int for int,str in vocab.items()}\n",
    "        self.str_to_int=vocab\n",
    "        \n",
    "    def encode(self, text):\n",
    "        preprocessed= re.split(r'([.,?!_!\"()\\']|--|\\s)',text)\n",
    "        _preprocessed= [items.strip() for items in preprocessed if items.split()]\n",
    "        encoded_text= [item if item in self.str_to_int \n",
    "                       else \"<|unk|>\" for item in _preprocessed]\n",
    "        return [self.str_to_int[items] for items in encoded_text]\n",
    "    \n",
    "    def decode(self, tokens):\n",
    "        text= \" \".join([self.int_to_str[items] for items in tokens])\n",
    "        text= re.sub(r'\\s([,.:?_!\"()\\']|--|\\s)',r'\\1',text)\n",
    "        return text \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1143, 705, 1143, 590, 1143]\n",
      "<|unk|> my <|unk|> is <|unk|>\n"
     ]
    }
   ],
   "source": [
    "tokenizer2= simpleTokenizer2(vocab)\n",
    "text=\"Hello my name is Anant\"\n",
    "encoded= tokenizer2.encode(text)\n",
    "print(encoded)\n",
    "decode= tokenizer2.decode(encoded)\n",
    "print(decode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Byte-Pair Encoding --> A type of subword encoding technique used in GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "tokenizer= tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing dataset, Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDataset_V1:\n",
    "    \n",
    "    def __init__(self, text, tokenizer, maximum_length, stride):\n",
    "        \n",
    "        self.input_ids=[]\n",
    "        self.target_ids=[] \n",
    "        \n",
    "        token_ids= tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "        \n",
    "        for i in range(0, len(token_ids)-maximum_length, stride):\n",
    "            input_tokens = token_ids[i:i+maximum_length]\n",
    "            output_tokens= token_ids[i+1:i+maximum_length+1]\n",
    "            \n",
    "            self.input_ids.append(torch.tensor(input_tokens))\n",
    "            self.target_ids.append(torch.tensor(output_tokens))\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.input_ids[index], self.target_ids[index]\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_Dataloader_V1(text, batch_size=4, maximum_length=256, stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
    "    \n",
    "    tokenizer=tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset= GPTDataset_V1(text, tokenizer, maximum_length, stride)\n",
    "\n",
    "    dataloader= DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers)\n",
    "    \n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size= 50257\n",
    "output_dim=256\n",
    "\n",
    "embedding_layer= torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length=4 \n",
    "dataLoader= Create_Dataloader_V1(raw_text, \n",
    "                                batch_size=8, \n",
    "                                maximum_length=max_length, \n",
    "                                stride=max_length, shuffle=False)\n",
    "data_iter= iter(dataLoader)\n",
    "inputs, targets= next(data_iter)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Ids: \n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token Ids: \\n\", inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inputs shape\n",
      " torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nInputs shape\\n\", inputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Self_Attention_V1:\n",
    "    \n",
    "    def __init__(self, d_in, d_out, qkv_biases=False):\n",
    "        super.__init__()\n",
    "        self.w_query=torch.Parameter(torch.nn.random(d_in, d_out, bias=qkv_biases))\n",
    "        self.w_key=torch.Parameter(torch.nn.random(d_in, d_out, bias=qkv_biases))\n",
    "        self.w_value=torch.Parameter(torch.nn.random(d_in, d_out, bias=qkv_biases))\n",
    "        \n",
    "        def forward(self, x):\n",
    "            \n",
    "            queries=self.w_query(x)\n",
    "            keys=self.w_key(x)\n",
    "            values=self.w_values(x)\n",
    "            \n",
    "            # attention= softmax([1/sqrt(d_out)*query*key^T])*value\n",
    "            \n",
    "            attention_scores= queries @ keys.T\n",
    "            attention_weight= torch.softmax(attention_scores/ keys.shape[-1]**0.5, dim=-1)\n",
    "            context_vec= attention_weight @ values\n",
    "            \n",
    "            return context_vec\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Self_Attention_V2(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_in, d_out, qkv_biases=False):\n",
    "        super.__init__()\n",
    "        self.w_query=nn.Linear(d_in, d_out, bias=qkv_biases)\n",
    "        self.w_key=nn.Linear(d_in, d_out, bias=qkv_biases)\n",
    "        self.w_values=nn.Linear(d_in, d_out, bias=qkv_biases)\n",
    "        \n",
    "        def forward(self, x):\n",
    "            \n",
    "            queries=self.w_query(x)\n",
    "            keys=self.w_key(x)\n",
    "            values=self.w_values(x)\n",
    "            \n",
    "            # attention= softmax([1/sqrt(d_out)*query*key^T])*value\n",
    "            \n",
    "            attention_scores= queries @ keys.T\n",
    "            attention_weight= torch.softmax(attention_scores/ keys.shape[-1]**0.5, dim=-1)\n",
    "            context_vec= attention_weight @ values\n",
    "            \n",
    "            return context_vec\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Causal attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Causal_Attention(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_in, d_out, context_length, dropout, qkv_biases=False):\n",
    "        super.__init__()\n",
    "        self.d_out=d_out\n",
    "        self.w_query=nn.Linear(d_in, d_out, bias=qkv_biases)\n",
    "        self.w_key=nn.Linear(d_in, d_out, bias=qkv_biases)\n",
    "        self.w_values=nn.Linear(d_in, d_out, bias=qkv_biases)\n",
    "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "        self.droout= nn.Dropout(dropout)\n",
    "        \n",
    "        def forward(self, x):\n",
    "            batch_size, num_tokens, d_in= x.shape\n",
    "            queries=self.w_query(x)\n",
    "            keys=self.w_key(x)\n",
    "            values=self.w_values(x)\n",
    "            \n",
    "            # attention= softmax([1/sqrt(d_out)*query*key^T])*value\n",
    "            \n",
    "            attention_scores= queries @ keys.transpose(1,2)\n",
    "            attention_scores.masked_fill_(\n",
    "                self.mask.bool()[:num_tokens,:num_tokens],-torch.inf\n",
    "            )\n",
    "            attention_weight= torch.softmax(attention_scores/ keys.shape[-1]**0.5, dim=-1)\n",
    "            attention_weight= self.dropout(attention_weight)\n",
    "            context_vec= attention_weight @ values\n",
    "            \n",
    "            return context_vec\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-head attention wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiheadAttentionWrapper:\n",
    "    \n",
    "    def __init__(self, d_in, d_out, context_length, num_heads, dropout,qkv_biases=False):\n",
    "        self.heads=nn.ModuleList([\n",
    "            Causal_Attention(d_in, d_out, context_length, dropout, qkv_biases) for _ in range(num_heads)]\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        combined_context_vec= torch.cat([head(x) for head in self.heads], dim=-1)\n",
    "        return combined_context_vec\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm:\n",
    "    def __init__(self, embedding_dim):\n",
    "        super.__init__()\n",
    "        self.scale= nn.Parameter(torch.ones(embedding_dim))\n",
    "        self.shift= nn.Parameter(torch.ones(embedding_dim))\n",
    "        self.eps=1e-5\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean= x.mean( dim=-1, keepdim=True)\n",
    "        var= x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x= (x-mean)/torch.sqrt(var+self.eps)\n",
    "        return norm_x*self.scale+ self.shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multihead Attention with weight splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiheadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "            \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                       diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        \n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2) \n",
    "        \n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec) # optional projection\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-2 Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"emb_dim\": 768,         # Embedding dimension\n",
    "    \"n_heads\": 12,          # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of layers\n",
    "    \"drop_rate\": 0.1,       # Dropout rate\n",
    "    \"qkv_bias\": False       # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer-Norm, Feed Forward Neural Network, GELU Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "    \n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1+torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0/torch.pi)) *\n",
    "            (x + 0.044715 * torch.pow(x,3))))\n",
    "            \n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers=nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4*cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4*cfg[\"emb_dim\"], cfg[\"emb_dim\"])\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlocks(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.attn= MultiheadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out= cfg[\"emb_dim\"],\n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            qkv_bias= cfg[\"qkv_bias\"],\n",
    "            context_length= cfg[\"context_length\"]\n",
    "        )\n",
    "        self.norm1= LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2= LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.ff= FeedForward(cfg)\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        shortcut= x\n",
    "        x= self.norm1(x)\n",
    "        x= self.attn(x)\n",
    "        x= self.drop_shortcut(x)\n",
    "        x= x+shortcut\n",
    "        \n",
    "        shortcut=x\n",
    "        x= self.norm2(x)\n",
    "        x= self.ff(x)\n",
    "        x= self.drop_shortcut(x)\n",
    "        \n",
    "        x= x+shortcut\n",
    "        return x           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.tok_emb= nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb= nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb= nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        self.trf_blocks=nn.Sequential(\n",
    "            *[TransformerBlocks(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head= nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "        \n",
    "    \n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_length= in_idx.shape\n",
    "        tok_embeds= self.tok_emb(in_idx)\n",
    "        pos_embeds= self.pos_emb(torch.arange(seq_length,device=in_idx.device))\n",
    "        x= tok_embeds+ pos_embeds\n",
    "        x= self.drop_emb(x)\n",
    "        x=self.trf_blocks(x)\n",
    "        x=self.final_norm(x)\n",
    "        logits= self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "\n",
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[ 0.1381,  0.0077, -0.1963,  ..., -0.0222, -0.1060,  0.1717],\n",
      "         [ 0.3865, -0.8408, -0.6564,  ..., -0.5163,  0.2369, -0.3357],\n",
      "         [ 0.6989, -0.1829, -0.1631,  ...,  0.1472, -0.6504, -0.0056],\n",
      "         [-0.4290,  0.1669, -0.1258,  ...,  1.1579,  0.5303, -0.5549]],\n",
      "\n",
      "        [[ 0.1094, -0.2894, -0.1467,  ..., -0.0557,  0.2911, -0.2824],\n",
      "         [ 0.0882, -0.3552, -0.3527,  ...,  1.2930,  0.0053,  0.1898],\n",
      "         [ 0.6091,  0.4702, -0.4094,  ...,  0.7688,  0.3787, -0.1974],\n",
      "         [-0.0612, -0.0737,  0.4751,  ...,  1.2463, -0.3834,  0.0609]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "out = model(batch)\n",
    "print(\"Input batch:\\n\", batch)\n",
    "print(\"\\nOutput shape:\", out.shape)\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
